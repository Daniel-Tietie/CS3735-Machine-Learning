{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNN6R1JoQ0WzXMxICMntp/d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n"],"metadata":{"id":"yi-wqNT0AW6O","executionInfo":{"status":"ok","timestamp":1767100494828,"user_tz":-60,"elapsed":40,"user":{"displayName":"Daniel","userId":"04551067681022572009"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class DecisionTreeNode:\n","    def __init__(self):\n","        self.feature_index = None\n","        self.threshold = None\n","        self.left = None\n","        self.right = None\n","        self.value = None\n","\n","class CustomDecisionTree:\n","    def __init__(self, max_depth=None, max_features=None):\n","        self.max_depth = max_depth\n","        self.max_features = max_features\n","        self.root = None\n","\n","    def fit(self, X, y):\n","        self.n_classes = len(np.unique(y))\n","        self.n_features = X.shape[1]\n","        self.root = self._grow_tree(X, y)\n","\n","    def _grow_tree(self, X, y, depth=0):\n","        n_samples, n_features = X.shape\n","        node = DecisionTreeNode()\n","\n","        # Stopping criteria\n","        if len(y) == 0 or (self.max_depth is not None and depth >= self.max_depth) or len(np.unique(y)) == 1:\n","            node.value = self._most_common_label(y)\n","            return node\n","\n","        # Select random subset of features\n","        if self.max_features is not None:\n","            n_features_to_sample = min(self.max_features, n_features)\n","            feature_indices = np.random.choice(n_features, n_features_to_sample, replace=False)\n","        else:\n","            feature_indices = range(n_features)\n","\n","        # Find best split from selected features\n","        best_gain = -1\n","        best_feature = None\n","        best_threshold = None\n","\n","        for feature in feature_indices:\n","            thresholds = np.unique(X[:, feature])\n","            for threshold in thresholds:\n","                gain = self._information_gain(y, X[:, feature], threshold)\n","                if gain > best_gain:\n","                    best_gain = gain\n","                    best_feature = feature\n","                    best_threshold = threshold\n","\n","        if best_gain == -1:\n","            node.value = self._most_common_label(y)\n","            return node\n","\n","        # Create child nodes\n","        left_mask = X[:, best_feature] <= best_threshold\n","        right_mask = ~left_mask\n","\n","        # Don't split if it creates empty nodes\n","        if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n","            node.value = self._most_common_label(y)\n","            return node\n","\n","        node.feature_index = best_feature\n","        node.threshold = best_threshold\n","        node.left = self._grow_tree(X[left_mask], y[left_mask], depth + 1)\n","        node.right = self._grow_tree(X[right_mask], y[right_mask], depth + 1)\n","\n","        return node\n","\n","    def _information_gain(self, y, feature, threshold):\n","        parent_entropy = self._entropy(y)\n","\n","        left_mask = feature <= threshold\n","        right_mask = ~left_mask\n","\n","        if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n","            return 0\n","\n","        n = len(y)\n","        n_l, n_r = len(y[left_mask]), len(y[right_mask])\n","        e_l, e_r = self._entropy(y[left_mask]), self._entropy(y[right_mask])\n","        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n","\n","        return parent_entropy - child_entropy\n","\n","    def _entropy(self, y):\n","        if len(y) == 0:\n","            return 0\n","        hist = np.bincount(y)\n","        ps = hist / len(y)\n","        return -np.sum([p * np.log(p) for p in ps if p > 0])\n","\n","    def _most_common_label(self, y):\n","        if len(y) == 0:\n","            return 0\n","        return Counter(y).most_common(1)[0][0]\n","\n","    def predict(self, X):\n","        return np.array([self._traverse_tree(x, self.root) for x in X])\n","\n","    def _traverse_tree(self, x, node):\n","        if node.value is not None:\n","            return node.value\n","\n","        if x[node.feature_index] <= node.threshold:\n","            return self._traverse_tree(x, node.left)\n","        return self._traverse_tree(x, node.right)\n","\n","class CustomRandomForest:\n","    def __init__(self, n_trees=10, max_depth=None, max_features=None):\n","        self.n_trees = n_trees\n","        self.max_depth = max_depth\n","        self.max_features = max_features\n","        self.trees = []\n","\n","    def fit(self, X, y):\n","        self.trees = []\n","\n","        # Default: sqrt(n_features) for classification\n","        if self.max_features is None:\n","            self.max_features = int(np.sqrt(X.shape[1]))\n","\n","        for _ in range(self.n_trees):\n","            # Bootstrap sampling\n","            indices = np.random.choice(len(X), size=len(X), replace=True)\n","            sample_X = X[indices]\n","            sample_y = y[indices]\n","\n","            # Train tree with random feature subset\n","            tree = CustomDecisionTree(max_depth=self.max_depth, max_features=self.max_features)\n","            tree.fit(sample_X, sample_y)\n","            self.trees.append(tree)\n","\n","    def predict(self, X):\n","        # Get predictions from all trees\n","        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n","        # Majority vote\n","        return np.array([Counter(predictions).most_common(1)[0][0]\n","                        for predictions in tree_predictions.T])"],"metadata":{"id":"4tOWzhQgZErR","executionInfo":{"status":"ok","timestamp":1767100495668,"user_tz":-60,"elapsed":806,"user":{"displayName":"Daniel","userId":"04551067681022572009"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Load and prepare data\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"\n","column_names = ['lettr'] + [f'x{i}' for i in range(1, 17)]\n","data = pd.read_csv(url, names=column_names)\n","\n","print(\"Dataset shape:\", data.shape)\n","\n","# Convert letters to numbers\n","label_map = {letter: i for i, letter in enumerate(data['lettr'].unique())}\n","y = data['lettr'].map(label_map).values\n","X = data.drop('lettr', axis=1).values\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train custom random forest\n","print(\"\\nTraining Custom Random Forest...\")\n","custom_rf = CustomRandomForest(n_trees=25, max_depth=12)\n","custom_rf.fit(X_train, y_train)\n","custom_predictions = custom_rf.predict(X_test)\n","\n","accuracy = np.mean(custom_predictions == y_test)\n","print(f\"\\nCustom Random Forest Accuracy: {accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LkdVhoTZWN3","executionInfo":{"status":"ok","timestamp":1767100546603,"user_tz":-60,"elapsed":50918,"user":{"displayName":"Daniel","userId":"04551067681022572009"}},"outputId":"f677457d-4c46-4dee-f77a-d4a6640cda70"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset shape: (20000, 17)\n","\n","Training Custom Random Forest...\n","\n","Custom Random Forest Accuracy: 0.9355\n"]}]}]}