{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEiL-NVKaqaY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "iris_df = pd.read_csv(\"/content/sample_data/Iris.csv\")\n",
        "customer_df = pd.read_csv(\"/content/sample_data/Customer Purchasing Behaviors.csv\")\n",
        "\n",
        "print(\"Customer data shape:\", customer_df.shape)\n",
        "print(\"Iris data shape:\", iris_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IKuho3-fCl2",
        "outputId": "57ec85f6-2c99-4e8f-925d-e2cd71407af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer data shape: (238, 7)\n",
            "Iris data shape: (150, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare customer data for linear regression\n",
        "print(\"\\n--- Linear Regression (Customer Loyalty) ---\")\n",
        "customer_df.drop(columns=['user_id'], inplace=True)\n",
        "customer_df = pd.get_dummies(customer_df, columns=['region'], drop_first=True)\n",
        "\n",
        "X_cust = customer_df.drop(columns=['loyalty_score'])\n",
        "y_cust = customer_df['loyalty_score']\n",
        "\n",
        "X_train_cust, X_test_cust, y_train_cust, y_test_cust = train_test_split(\n",
        "    X_cust, y_cust, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# normalize features to prevent numerical issues in gradient descent\n",
        "X_train_mean = X_train_cust.mean()\n",
        "X_train_std = X_train_cust.std()\n",
        "X_train_cust_norm = (X_train_cust - X_train_mean) / X_train_std\n",
        "X_test_cust_norm = (X_test_cust - X_train_mean) / X_train_std\n",
        "\n",
        "# Linear Regression from scratch\n",
        "class SimpleLinearRegression:\n",
        "    def __init__(self, lr=0.01, epochs=1000):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Gradient descent\n",
        "        for _ in range(self.epochs):\n",
        "            y_predicted = np.dot(X, self.weights) + self.bias\n",
        "            dw = (1/n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1/n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "#train custom linear regression\n",
        "lin_reg_custom = SimpleLinearRegression(lr=0.01, epochs=5000)\n",
        "lin_reg_custom.fit(X_train_cust_norm.values.astype(float), y_train_cust.values.astype(float))\n",
        "y_pred_custom = lin_reg_custom.predict(X_test_cust_norm.values.astype(float))\n",
        "\n",
        "rmse_custom = np.sqrt(mean_squared_error(y_test_cust, y_pred_custom))\n",
        "print(f\"Custom Linear Regression RMSE: {rmse_custom:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uycf8RV0fRA1",
        "outputId": "49fee663-34ea-4d0f-bf40-9759b56c4c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Linear Regression (Customer Loyalty) ---\n",
            "Custom Linear Regression RMSE: 0.2011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare iris data for logistic regression\n",
        "print(\"\\n--- Logistic Regression (Iris Classification) ---\")\n",
        "iris_df.drop(columns=['Id'], inplace=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "iris_df['Species'] = label_encoder.fit_transform(iris_df['Species'])\n",
        "\n",
        "X_iris = iris_df.drop(columns=['Species'])\n",
        "y_iris = iris_df['Species']\n",
        "\n",
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
        "    X_iris, y_iris, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Logistic Regression from scratch (multi-class using One-vs-Rest)\n",
        "class SimpleLogisticRegression:\n",
        "    def __init__(self, lr=0.01, epochs=1000):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = {}  # one set of weights per class\n",
        "        self.bias = {}\n",
        "        self.classes = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        z = np.clip(z, -500, 500)  # prevent overflow\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.classes = np.unique(y)\n",
        "\n",
        "        # Train separate binary classifier for each class\n",
        "        for cls in self.classes:\n",
        "            y_binary = (y == cls).astype(int)\n",
        "            self.weights[cls] = np.zeros(n_features)\n",
        "            self.bias[cls] = 0\n",
        "\n",
        "            # Gradient descent for this class\n",
        "            for _ in range(self.epochs):\n",
        "                linear_model = np.dot(X, self.weights[cls]) + self.bias[cls]\n",
        "                y_predicted = self.sigmoid(linear_model)\n",
        "                dw = (1/n_samples) * np.dot(X.T, (y_predicted - y_binary))\n",
        "                db = (1/n_samples) * np.sum(y_predicted - y_binary)\n",
        "                self.weights[cls] -= self.lr * dw\n",
        "                self.bias[cls] -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for sample in X:\n",
        "            # Get the score from each classifier\n",
        "            class_scores = {}\n",
        "            for cls in self.classes:\n",
        "                linear_model = np.dot(sample, self.weights[cls]) + self.bias[cls]\n",
        "                class_scores[cls] = self.sigmoid(linear_model)\n",
        "            # Pick class with highest score\n",
        "            predictions.append(max(class_scores, key=class_scores.get))\n",
        "        return np.array(predictions)\n",
        "\n",
        "# Train custom logistic regression\n",
        "log_reg_custom = SimpleLogisticRegression(lr=0.1, epochs=1000)\n",
        "log_reg_custom.fit(X_train_iris.values.astype(float), y_train_iris.values.astype(int))\n",
        "y_pred_custom_log = log_reg_custom.predict(X_test_iris.values.astype(float))\n",
        "\n",
        "acc_custom = accuracy_score(y_test_iris, y_pred_custom_log)\n",
        "print(f\"Custom Logistic Regression Accuracy: {acc_custom:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J7ehs94-fNo",
        "outputId": "e59296e2-4841-41b7-c8b7-5903aac330a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Logistic Regression (Iris Classification) ---\n",
            "Custom Logistic Regression Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}